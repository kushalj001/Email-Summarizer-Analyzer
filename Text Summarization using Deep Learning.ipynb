{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization\n",
    "**Author** - Kushal \n",
    "* An extractive text summarization technique has been implemented.The procedure is as follows:\n",
    "    * First we obtain vector representation of all the sentences in our document/paragraph. A vector representation or sentence embeddings are obtained by training complex neural net architectures inlvolving transformers, LSTM etc on a large corpus of data(e.g. wikipedia dump) in an unsupervised way. I have used BERT for this (explained later).\n",
    "    * These sentence embeddings are then clustered into, say k clusters where k is the number of desired sentences in the summary. k can be square root of original number of sentences in the text or 30% of it. I did this using K-means from sklearn.\n",
    "    * Once clustered the cluster centers can be accessed. These cluster centers represent or convey the overall meaning of all the sentences that fall in the corresponding cluster.\n",
    "    * The representative sentence is decided by calculating the most similar sentence to each of the cluster center. This has been done using cosine similarity.\n",
    "\n",
    "* **BERT**\n",
    "  (Bidirectional Encoder Representations for Transformers) was a breakthrough paper in 2018 and was discovered by Google. It outperformed all the then existing SOTA architectures in a number of NLP tasks. It uses the transformer's structure to encode sentences. The representations generated by BERT are contextualized, i.e they take into consideration the context of the word used in the sentence. Earlier pre-trained embeddings like word2vec and glove were context-free.\n",
    "* I have used the following library to generate sentence embeddings : https://github.com/hanxiao/bert-as-service\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langdetect import detect,detect_langs\n",
    "from nltk import sent_tokenize\n",
    "from bert_serving.client import BertClient\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./eng_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Emails</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merci pour votre message! Malheureusement, mon...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>この問題についてご連絡いただきありがとうございます。 申し訳ありませんが私は日本語語が話せま...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grazie mille per aver trovato il tempo per met...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned Emails lang\n",
       "0  Merci pour votre message! Malheureusement, mon...   en\n",
       "2  この問題についてご連絡いただきありがとうございます。 申し訳ありませんが私は日本語語が話せま...   en\n",
       "3  Grazie mille per aver trovato il tempo per met...   en\n",
       "4  Thank you so much for reaching out and taking ...   en\n",
       "5  Thank you so much for reaching out and taking ...   en"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\bert_serving\\client\\__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "bert = BertClient()\n",
    "def get_embeddings(row):\n",
    "    '''Generates bert sentence embeddings.Bert server is open in the terminal.'''\n",
    "    \n",
    "    text = row['Cleaned Emails']\n",
    "    sents = sent_tokenize(text)\n",
    "    embeddings = bert.encode(sents)\n",
    "    return embeddings\n",
    "\n",
    "df['Embeddings'] = df.apply(get_embeddings,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Emails</th>\n",
       "      <th>lang</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merci pour votre message! Malheureusement, mon...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.17367607, 0.06847995, 0.1780457, -0.28497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>この問題についてご連絡いただきありがとうございます。 申し訳ありませんが私は日本語語が話せま...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.14160722, -0.5160878, 0.37131366, 0.02110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grazie mille per aver trovato il tempo per met...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.7721293, -0.2312476, 1.1882508, -0.083789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.114546, -0.41043538, 0.4535624, 0.09567887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.114546, -0.41043538, 0.4535624, 0.09567887...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned Emails lang  \\\n",
       "0  Merci pour votre message! Malheureusement, mon...   en   \n",
       "2  この問題についてご連絡いただきありがとうございます。 申し訳ありませんが私は日本語語が話せま...   en   \n",
       "3  Grazie mille per aver trovato il tempo per met...   en   \n",
       "4  Thank you so much for reaching out and taking ...   en   \n",
       "5  Thank you so much for reaching out and taking ...   en   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [[-0.17367607, 0.06847995, 0.1780457, -0.28497...  \n",
       "2  [[-0.14160722, -0.5160878, 0.37131366, 0.02110...  \n",
       "3  [[-0.7721293, -0.2312476, 1.1882508, -0.083789...  \n",
       "4  [[0.114546, -0.41043538, 0.4535624, 0.09567887...  \n",
       "5  [[0.114546, -0.41043538, 0.4535624, 0.09567887...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_centers(row):\n",
    "    ''' \n",
    "    Performs clustering of sentences in the text. Number of clusters or the number of required sentences in summary\n",
    "    is the square root of total sentences in the text.Returns cluster centers.\n",
    "    '''\n",
    "    \n",
    "    text = row['Cleaned Emails']\n",
    "    sents = sent_tokenize(text)\n",
    "    clusters = int(np.ceil(len(sents)**0.5))\n",
    "    embeddings = row['Embeddings']\n",
    "    kmeans = KMeans(n_clusters=clusters).fit(embeddings)\n",
    "    \n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "df['Cluster Centers'] = df.apply(get_cluster_centers,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Emails</th>\n",
       "      <th>lang</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Cluster Centers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merci pour votre message! Malheureusement, mon...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.17367607, 0.06847995, 0.1780457, -0.28497...</td>\n",
       "      <td>[[-0.42146394, 0.30830446, 0.1823968, -0.21394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>この問題についてご連絡いただきありがとうございます。 申し訳ありませんが私は日本語語が話せま...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.14160722, -0.5160878, 0.37131366, 0.02110...</td>\n",
       "      <td>[[-0.14160722, -0.5160878, 0.37131366, 0.02110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grazie mille per aver trovato il tempo per met...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.7721293, -0.2312476, 1.1882508, -0.083789...</td>\n",
       "      <td>[[0.12635724, -0.29532984, 0.37011546, 0.21694...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.114546, -0.41043538, 0.4535624, 0.09567887...</td>\n",
       "      <td>[[0.16755143, -0.06252824, 0.43795574, 0.03444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.114546, -0.41043538, 0.4535624, 0.09567887...</td>\n",
       "      <td>[[-0.007928453, -0.075849526, 0.17494668, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned Emails lang  \\\n",
       "0  Merci pour votre message! Malheureusement, mon...   en   \n",
       "2  この問題についてご連絡いただきありがとうございます。 申し訳ありませんが私は日本語語が話せま...   en   \n",
       "3  Grazie mille per aver trovato il tempo per met...   en   \n",
       "4  Thank you so much for reaching out and taking ...   en   \n",
       "5  Thank you so much for reaching out and taking ...   en   \n",
       "\n",
       "                                          Embeddings  \\\n",
       "0  [[-0.17367607, 0.06847995, 0.1780457, -0.28497...   \n",
       "2  [[-0.14160722, -0.5160878, 0.37131366, 0.02110...   \n",
       "3  [[-0.7721293, -0.2312476, 1.1882508, -0.083789...   \n",
       "4  [[0.114546, -0.41043538, 0.4535624, 0.09567887...   \n",
       "5  [[0.114546, -0.41043538, 0.4535624, 0.09567887...   \n",
       "\n",
       "                                     Cluster Centers  \n",
       "0  [[-0.42146394, 0.30830446, 0.1823968, -0.21394...  \n",
       "2  [[-0.14160722, -0.5160878, 0.37131366, 0.02110...  \n",
       "3  [[0.12635724, -0.29532984, 0.37011546, 0.21694...  \n",
       "4  [[0.16755143, -0.06252824, 0.43795574, 0.03444...  \n",
       "5  [[-0.007928453, -0.075849526, 0.17494668, -0.0...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(row):\n",
    "    '''\n",
    "    Generates summary by choosing the sentences in the text that are closest to the centroid.\n",
    "    '''\n",
    "    text = row['Cleaned Emails']\n",
    "    sents = sent_tokenize(text)\n",
    "    centroids = row['Cluster Centers']\n",
    "    embeddings = row['Embeddings']\n",
    "    clusters = centroids.shape[0]\n",
    "    sents_len = len(sents)\n",
    "    summary = []\n",
    "    for i in range(clusters):\n",
    "        select = -1\n",
    "        m = -np.inf\n",
    "        for j in range(sents_len):\n",
    "            similarity = np.dot(centroids[i],embeddings[j])\n",
    "            if similarity > m:\n",
    "                m = similarity\n",
    "                select = j\n",
    "        summary.append(select)\n",
    "    summary.sort()\n",
    "    summary = ''.join([sents[i] for i in summary])\n",
    "    return summary\n",
    "    \n",
    "df['Summary'] = df.apply(get_summary,axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Emails</th>\n",
       "      <th>lang</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Cluster Centers</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merci pour votre message! Malheureusement, mon...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.17367607, 0.06847995, 0.1780457, -0.28497...</td>\n",
       "      <td>[[-0.42146394, 0.30830446, 0.1823968, -0.21394...</td>\n",
       "      <td>J'espère que ça ne vous dérange pas, mais je v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grazie mille per aver trovato il tempo per met...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[-0.7721293, -0.2312476, 1.1882508, -0.083789...</td>\n",
       "      <td>[[0.12635724, -0.29532984, 0.37011546, 0.21694...</td>\n",
       "      <td>Grazie mille per aver trovato il tempo per met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.114546, -0.41043538, 0.4535624, 0.09567887...</td>\n",
       "      <td>[[0.16755143, -0.06252824, 0.43795574, 0.03444...</td>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.114546, -0.41043538, 0.4535624, 0.09567887...</td>\n",
       "      <td>[[-0.007928453, -0.075849526, 0.17494668, -0.0...</td>\n",
       "      <td>If you can access   via Touch ID you can simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thank you so much for reaching out and taking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[[0.33351135, -0.31490558, 0.3397996, 0.299524...</td>\n",
       "      <td>[[-0.08749674, -0.29593503, 0.05410941, 0.1850...</td>\n",
       "      <td>We really appreciate it and are happy to hear ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned Emails lang  \\\n",
       "0  Merci pour votre message! Malheureusement, mon...   en   \n",
       "3  Grazie mille per aver trovato il tempo per met...   en   \n",
       "4  Thank you so much for reaching out and taking ...   en   \n",
       "5  Thank you so much for reaching out and taking ...   en   \n",
       "8  Thank you so much for reaching out and taking ...   en   \n",
       "\n",
       "                                          Embeddings  \\\n",
       "0  [[-0.17367607, 0.06847995, 0.1780457, -0.28497...   \n",
       "3  [[-0.7721293, -0.2312476, 1.1882508, -0.083789...   \n",
       "4  [[0.114546, -0.41043538, 0.4535624, 0.09567887...   \n",
       "5  [[0.114546, -0.41043538, 0.4535624, 0.09567887...   \n",
       "8  [[0.33351135, -0.31490558, 0.3397996, 0.299524...   \n",
       "\n",
       "                                     Cluster Centers  \\\n",
       "0  [[-0.42146394, 0.30830446, 0.1823968, -0.21394...   \n",
       "3  [[0.12635724, -0.29532984, 0.37011546, 0.21694...   \n",
       "4  [[0.16755143, -0.06252824, 0.43795574, 0.03444...   \n",
       "5  [[-0.007928453, -0.075849526, 0.17494668, -0.0...   \n",
       "8  [[-0.08749674, -0.29593503, 0.05410941, 0.1850...   \n",
       "\n",
       "                                             Summary  \n",
       "0  J'espère que ça ne vous dérange pas, mais je v...  \n",
       "3  Grazie mille per aver trovato il tempo per met...  \n",
       "4  Thank you so much for reaching out and taking ...  \n",
       "5  If you can access   via Touch ID you can simpl...  \n",
       "8  We really appreciate it and are happy to hear ...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./finaldf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much for reaching out and taking the time to contact us about this issue! Please excuse the delayed response. I'm happy to inform you that you can already enlarge the front and back pictures of your cards simply by tapping on it once. Your card pictures will then get enlarged as well as rotated. However, I will also suggest to our developers to make zooming already in the \"Notes\" tab possible for future versions of  . I hope I was able to help you. If you have any further questions, suggestions for improvements or general feedback, please don't hesitate to contact me again.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Thank you so much for reaching out and taking the time to contact us about this issue!However, I will also suggest to our developers to make zooming already in the \"Notes\" tab possible for future versions of  .If you have any further questions, suggestions for improvements or general feedback, please don't hesitate to contact me again.\n"
     ]
    }
   ],
   "source": [
    "print(df['Cleaned Emails'][4])\n",
    "print('-'*120)\n",
    "print(df['Summary'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much for reaching out and taking the time to send us feedback! We really appreciate it and are happy to hear that you like our app!We are aware that the current loading times of our app have increased over the course of the latest updates and I can assure you that our developers are already working on improving the speed and overall performance again for future releases. Until then, you could try keeping   opened in the background while shopping as a temporary workaround. This way, the app doesn't have to reload all your information (e.g. card pictures, points balances, etc.) completely each time it is opened and the loading times will be decreased significantly. In the meantime, I sincerely apologize for the inconvenience this causes and hope that you can use   in its full capacity again soon.If you have any further questions, suggestions for improvements or general feedback, please don't hesitate to contact me again.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "We really appreciate it and are happy to hear that you like our app!We are aware that the current loading times of our app have increased over the course of the latest updates and I can assure you that our developers are already working on improving the speed and overall performance again for future releases.card pictures, points balances, etc.)completely each time it is opened and the loading times will be decreased significantly.\n"
     ]
    }
   ],
   "source": [
    "print(df['Cleaned Emails'][8])\n",
    "print('-'*120)\n",
    "print(df['Summary'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
